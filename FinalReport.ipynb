{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade Results\n",
      "Grade Results\n",
      "Grade Results\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Exception thrown: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\gradelang\\gradelang\\interpreter.py\", line 49, in worker\n",
      "    walk(question.body)\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 194, in walk\n",
      "    return dispatch[action](ast)\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 108, in <lambda>\n",
      "    'seq': lambda ast: (walk(ast[1]), walk(ast[2])),\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 194, in walk\n",
      "    return dispatch[action](ast)\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 114, in <lambda>\n",
      "    'assert': lambda ast: _assert(ast[1]),\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 102, in _assert\n",
      "    raise AssertionError\n",
      "AssertionError\n",
      "\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question string: 0/10.\n",
      "Exception thrown: ValueError(\"Unknown node: ('paramlist', ('paramassign', 'minlen', ('integer', 10)), ('paramassign', 'maxlen', ('integer', 100)))\")\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\gradelang\\gradelang\\interpreter.py\", line 49, in worker\n",
      "    walk(question.body)\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 194, in walk\n",
      "    return dispatch[action](ast)\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 108, in <lambda>\n",
      "    'seq': lambda ast: (walk(ast[1]), walk(ast[2])),\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 194, in walk\n",
      "    return dispatch[action](ast)\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 69, in let\n",
      "    params = walk(ast[3])\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 195, in walk\n",
      "    raise ValueError(f\"Unknown node: {ast}\")\n",
      "ValueError: Unknown node: ('paramlist', ('paramassign', 'minlen', ('integer', 10)), ('paramassign', 'maxlen', ('integer', 100)))\n",
      "\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question named: 0/0.\n",
      "Grade Results\n",
      "Question 1: 0/0.\n",
      "Grade Results\n",
      "Grade Results\n",
      "Grade Results\n",
      "Grade Results\n",
      "{\n",
      "    \"tests\": []\n",
      "}\n",
      "# Results\n",
      "## Score: 0/0\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Exception thrown: AssertionError()\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\gradelang\\gradelang\\interpreter.py\", line 47, in worker\n",
      "    walk(setup)\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 194, in walk\n",
      "    return dispatch[action](ast)\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 108, in <lambda>\n",
      "    'seq': lambda ast: (walk(ast[1]), walk(ast[2])),\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 194, in walk\n",
      "    return dispatch[action](ast)\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 114, in <lambda>\n",
      "    'assert': lambda ast: _assert(ast[1]),\n",
      "  File \"D:\\gradelang\\gradelang\\walk.py\", line 102, in _assert\n",
      "    raise AssertionError\n",
      "AssertionError\n",
      "\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "LexToken(ID,'touch',142,29) (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\brit\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3319\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-3-bf6cd51e0afe>\"\u001b[0m, line \u001b[0;32m223\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    interpret(proposal)\n",
      "  File \u001b[0;32m\"D:\\gradelang\\gradelang\\interpreter.py\"\u001b[0m, line \u001b[0;32m20\u001b[0m, in \u001b[0;35minterpret\u001b[0m\n    parser.parse(stream, lexer=lexer)\n",
      "  File \u001b[0;32m\"C:\\Users\\brit\\Anaconda3\\lib\\site-packages\\ply\\yacc.py\"\u001b[0m, line \u001b[0;32m333\u001b[0m, in \u001b[0;35mparse\u001b[0m\n    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)\n",
      "  File \u001b[0;32m\"C:\\Users\\brit\\Anaconda3\\lib\\site-packages\\ply\\yacc.py\"\u001b[0m, line \u001b[0;32m1201\u001b[0m, in \u001b[0;35mparseopt_notrack\u001b[0m\n    tok = call_errorfunc(self.errorfunc, errtoken, self)\n",
      "  File \u001b[0;32m\"C:\\Users\\brit\\Anaconda3\\lib\\site-packages\\ply\\yacc.py\"\u001b[0m, line \u001b[0;32m192\u001b[0m, in \u001b[0;35mcall_errorfunc\u001b[0m\n    r = errorfunc(token)\n",
      "\u001b[1;36m  File \u001b[1;32m\"D:\\gradelang\\gradelang\\frontend_grammar.py\"\u001b[1;36m, line \u001b[1;32m313\u001b[1;36m, in \u001b[1;35mp_error\u001b[1;36m\u001b[0m\n\u001b[1;33m    raise SyntaxError(str(t))\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<string>\"\u001b[1;36m, line \u001b[1;32munknown\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m LexToken(ID,'touch',142,29)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gradelang\n",
    "\n",
    "Thomas Howard III\n",
    "Mary Wishart\n",
    "Brittany Lewis\n",
    "\n",
    "Introduction:\n",
    "\n",
    "Grade is an autograding framework for Python which provides more flexibility than traditional Python TestCases \n",
    "by allowing for arbitrarily complex testing conditions. Gradelang is a domain specific language for the Grade framework.\n",
    "It allows graders to create question structures to evaluate student executables. \n",
    "\n",
    "By creating Gradelang, we hope it will make it easier for teachers and graders to evaluate student code quickly, easily,\n",
    "and fairly. We also hope that the ease and flexibility of testing will create more space for creativity in assignment\n",
    "design.\n",
    "\n",
    "\n",
    "Implementation:\n",
    "\n",
    "\n",
    "Gradelang is broken up into block structures. There are four main types of blocks:\n",
    "\n",
    "- Setup: Statements in the setup block run before every question. Setup will most likely involve statements that\n",
    "         create necessary test files or check requirements for questions.\n",
    "- Teardown: Statements in the teardown block run after every question. This could include operations such as cleaning\n",
    "         up created files by deleting them.\n",
    "- Question: Each question block runs independently from each other question and allows the grader to specify tests\n",
    "            and award values associated with those questions.\n",
    "- Output: This block determines how the results of our program are outputted.\n",
    "\n",
    "Within those structures we support common arithmetic expressions as well as statements for file creation, \n",
    "variable assignment, arbitrary string, float, and int creation through the hypothesis framework. Most importantly\n",
    "tests and be run and tested through the run and assert commands which are supported through the Grade pipeline\n",
    "\n",
    "\n",
    "Challenges:\n",
    "\n",
    "One challenge we faced was making each question truly independent. In order to ensure that one question test failure\n",
    "would not affect any future tests (an important requirement for autograding) we run each question in a separate subprocess.\n",
    "\n",
    "This can cause issues for python 3.7.3 and python version 3.7.4 both of which have a bug within their subprocess handling. \n",
    "\n",
    "If you have issues with your subprocess run, please try updating your python installation to python 3.8. Further\n",
    "instructions and a docker image are also included. Please contact the project team with any problems you encounter.\n",
    "\n",
    "In addition to these challenges, we also had some challenges with getting hypothesis to work with the structure we wanted\n",
    "for our language. \n",
    "\n",
    "\n",
    "Examples:\n",
    "\n",
    "In order to run these examples you will need to have:\n",
    "\n",
    "- Python version 3.8\n",
    "- ply\n",
    "    - pip install ply\n",
    "- Grade \n",
    "    - pip install grade\n",
    "    - https://github.com/thoward27/grade\n",
    "- Hypothesis\n",
    "    - pip install Hypothesis\n",
    "    - https://hypothesis.readthedocs.io/en/latest/\n",
    "    \n",
    "In addition to the below examples we have a full suite of python unittests in the test folder of our project. \n",
    "\n",
    "\"\"\"\n",
    "from gradelang.interpreter import interpret\n",
    "\n",
    "# Basic setup tests\n",
    "empty = \"setup {}\"\n",
    "interpret(empty)\n",
    "\n",
    "trivial_passing = \"setup { assert 1 == 1; }\"\n",
    "interpret(trivial_passing)\n",
    "\n",
    "trivial_failing = \"setup { assert 1 == 0; }\"\n",
    "interpret(trivial_failing)\n",
    "\n",
    "\n",
    "#Question tests\n",
    "\n",
    "empty = \"question {}\"\n",
    "interpret(empty)\n",
    "\n",
    "trivial_passing = \"question { assert 1 == 1; }\"\n",
    "interpret(trivial_passing)\n",
    "\n",
    "trivial_failing = \"question { assert 0 == 1; }\"\n",
    "interpret(trivial_failing)\n",
    "\n",
    "testing_output = \"\"\"\n",
    "question {\n",
    "    run \"echo hello world\";\n",
    "    assert \"hello world\" in stdout;\n",
    "}\n",
    "\"\"\"\n",
    "interpret(testing_output)\n",
    "\n",
    "testing_exit_success = \"\"\"\n",
    "question {\n",
    "    run \"echo hello world\";\n",
    "    assert exit successful;\n",
    "}\n",
    "\"\"\"\n",
    "interpret(testing_exit_success)\n",
    "\n",
    "testing_create_string=\"\"\"\n",
    "    question \\\"string\\\"{\n",
    "        let x be String(minlen=10, maxlen=100);\n",
    "        run \"echo\", x;\n",
    "        assert x in stdout;\n",
    "        award 10;\n",
    "    }\n",
    "\"\"\"\n",
    "interpret(testing_create_string)\n",
    "\n",
    "interpret(testing_exit_success)\n",
    "\n",
    "name_string = 'question \"named\" {}'\n",
    "interpret(name_string)\n",
    "\n",
    "name_int = 'question 1 {}'\n",
    "interpret(name_int)\n",
    "\n",
    "#Teardown tests\n",
    "empty = \"teardown {}\"\n",
    "interpret(empty)\n",
    "\n",
    "trivial_passing = \"teardown { assert 1 == 1; }\"\n",
    "interpret(trivial_passing)\n",
    "\n",
    "trivial_failing = \"teardown { assert 0 == 1; }\"\n",
    "interpret(trivial_failing)\n",
    "\n",
    "#Output tests\n",
    "empty = \"output {}\"\n",
    "interpret(empty)\n",
    "\n",
    "json = 'output { json; }'\n",
    "interpret(json)\n",
    "\n",
    "markdown = 'output { markdown; }'\n",
    "interpret(markdown)\n",
    "\n",
    "#Testing programs\n",
    "empty =\"\"\"\n",
    "setup {}\n",
    "question {}\n",
    "teardown {}\n",
    "output {}\n",
    "\"\"\"\n",
    "interpret(empty)\n",
    "\n",
    "setup_failure = \"\"\"\n",
    "setup { assert 1 == 0; }\n",
    "question { assert 1 == 1; }\n",
    "teardown {}\n",
    "output {}\n",
    "\"\"\"\n",
    "interpret(setup_failure)\n",
    "\n",
    "proposal = \"\"\"\n",
    "        setup {\n",
    "            touch \"temp.txt\";\n",
    "            run \"echo\";\n",
    "            assert exit successful;\n",
    "        }\n",
    "\n",
    "        teardown {\n",
    "            remove \"temp.txt\";\n",
    "        }\n",
    "\n",
    "        output {\n",
    "            json;\n",
    "        }\n",
    "\n",
    "        output {\n",
    "        }\n",
    "            question 1 {\n",
    "            # Run the program, saving output.\n",
    "            run \"echo\", \"hello world\";\n",
    "\n",
    "            # Now let's run some checks.\n",
    "            assert exit successful;\n",
    "\n",
    "            # This checks both stdout and stderr\n",
    "            assert \"hello\" in stdout;\n",
    "\n",
    "            award 10;\n",
    "        }\n",
    "\n",
    "        question 2  {\n",
    "            run \"echo\", \"hello world\";\n",
    "            assert \"goodbye\" not in stdout;\n",
    "            award 10;\n",
    "            assert \"hello\" in stdout;\n",
    "            assert \"hello\" not in stderr;\n",
    "            award 10;\n",
    "        }\n",
    "\n",
    "        question 3 {\n",
    "            let x be Float(minvalue=1);\n",
    "            run \"echo\", x;\n",
    "\n",
    "            # If we want to just look at stdout.\n",
    "            assert x in stdout;\n",
    "            \n",
    "            String y = \"fish\";\n",
    "            run \"echo\", y;\n",
    "            assert \"fish\" in stdout;\n",
    "            \n",
    "            let z be String();\n",
    "            run \"echo\", z;\n",
    "            assert z in stdout;\n",
    "            \n",
    "            let camel be Int(min_value=6);\n",
    "            run \"echo\", camel;\n",
    "            assert camel in stdout;\n",
    "            \n",
    "            award 50;\n",
    "        }\n",
    "        \"\"\"\n",
    "interpret(proposal)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Conclusions:\n",
    "\n",
    "We successfully created a simple, easy to use language to work with the Grade autograding framework. We believe that this\n",
    "will make it easier to efficiently grade assignments. We also think our language will be natural and easy to learn\n",
    "for anyone who has used an autograder in the past.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
