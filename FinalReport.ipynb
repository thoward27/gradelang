{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradelang\n",
    "\n",
    "By: Thomas Howard III, Mary Wishart, Brittany Lewis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Grade is an autograding framework for Python which provides more flexibility than traditional Python TestCases by integrating binary testing directly into the language and removing the need for boilerplate code.\n",
    "Gradelang is a domain specific language which wraps the functionality of the Python package [Grade](https://github.com/thoward27/grade).\n",
    "It allows graders to create question structures to evaluate student executables, easily access content printed to `stdout` and `stderr`, check exit codes, and more.\n",
    "\n",
    "By creating Gradelang, we hope it will make it easier for teachers and graders to evaluate student code quickly, easily, and fairly.\n",
    "We also hope that the ease and flexibility of testing will create more space for creativity in assignment design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Gradelang is broken up into block structures.\n",
    "\n",
    "There are four main types of blocks:\n",
    "\n",
    "- Setup: Statements in the setup block run before every question. Setup will most likely involve statements that create necessary test files or check requirements for questions.\n",
    "- Teardown: Statements in the teardown block run after every question. This could include operations such as cleaning up created files by deleting them.\n",
    "- Question: Each question block runs independently from each other question and allows the grader to specify tests and award values associated with those questions.\n",
    "- Output: This block determines how the results of our program are outputted.\n",
    "\n",
    "Within those structures we support common arithmetic expressions as well as statements for file creation, variable assignment, arbitrary string, float, and int creation through the hypothesis framework. \n",
    "Most importantly tests and be run and tested through the run and assert commands which are supported through the Grade pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "### Independance\n",
    "\n",
    "One challenge we faced was making each question truly independent.\n",
    "In order to ensure that one question test failure would not affect any future tests (an important requirement for autograding) we run each question in a separate process, using Python's Multiprocessing library.\n",
    "In traditional unit tests, infinite loops, calls to exit, or other such severe mechanisms of failure can cause the output to be broken, showing only a subset of the tests provided.\n",
    "Gradelang has none of these problems.\n",
    "Since each question is run in a dedicated process, we can kill infinite loops elegantly, even calls to `exit()` within a test will not disrupt the final output.\n",
    "Gradelang guarentees students will see every test, every time.\n",
    "\n",
    "To complement the independant nature of each test, we also provide thread-safe storage solutions, strings prefixed with `@/` are treated as paths, and the `@` sybmol replaced by a dedicated workspace for the question currently running.\n",
    "\n",
    "\n",
    "### Python Bugs\n",
    "\n",
    "Unfortunately, another issue we ran into was embedded into Python itself.\n",
    "There exists a bug in Python (Issues [#31935](https://bugs.python.org/issue31935), [#30154](https://bugs.python.org/issue30154), [#37424](https://bugs.python.org/issue37424)), which required us to set a minimum version for Python at 3.7.5.\n",
    "We recommend using 3.8.0, which is what we built and tested on.\n",
    "\n",
    "Fortunately, if you do experience any issues with running gradelang, we do provide a Dockerfile preconfigured to work out of the box.\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "In addition to the challenges detailed above, we also had some difficulties getting hypothesis to work with the structure we wanted for our language.\n",
    "Gradelang provides a convenient wrapper to generate random values at runtime, using `let x be Type`.\n",
    "To do this, we use Hypothesis, a package designed for property-based testing in Python, which focuses on random value generation and shrinking to minimum failing cases.\n",
    "Currently, we generate only a single random value for each test, future work will aim to use hypothesis' shrinking functionality by generating many different random values and testing each one in turn.\n",
    "\n",
    "Please contact the project team with any problems you may encounter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "In order to run these examples, we recommend starting with Python 3.8, then installing the dependancies for the project.\n",
    "\n",
    "```\n",
    "python -m pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradelang.interpreter import interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade Results\n",
      "Grade Results\n",
      "Grade Results\n"
     ]
    }
   ],
   "source": [
    "# Basic setup tests\n",
    "empty = \"setup {}\"\n",
    "interpret(empty)\n",
    "\n",
    "trivial_passing = \"setup { assert 1 == 1; }\"\n",
    "interpret(trivial_passing)\n",
    "\n",
    "trivial_failing = \"setup { assert 1 == 0; }\"\n",
    "interpret(trivial_failing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Exception thrown: AssertionError(\"False was not true! ('==', ('integer', 0), ('integer', 1))\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tom/gradelang/gradelang/interpreter.py\", line 63, in worker\n",
      "    walk(question.body)\n",
      "  File \"/home/tom/gradelang/gradelang/walk.py\", line 151, in walk\n",
      "    return dispatch[action](ast)\n",
      "  File \"/home/tom/gradelang/gradelang/walk.py\", line 133, in <lambda>\n",
      "    'seq': lambda ast: (walk(ast[1]), walk(ast[2])),\n",
      "  File \"/home/tom/gradelang/gradelang/walk.py\", line 151, in walk\n",
      "    return dispatch[action](ast)\n",
      "  File \"/home/tom/gradelang/gradelang/walk.py\", line 60, in <lambda>\n",
      "    'assert': lambda ast: __assert(walk(ast[1]), ast[1]),\n",
      "  File \"/home/tom/gradelang/gradelang/walk.py\", line 50, in __assert\n",
      "    raise AssertionError(f'{cond} was not true! {message}')\n",
      "AssertionError: False was not true! ('==', ('integer', 0), ('integer', 1))\n",
      "\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question string: 10/10.\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question named: 0/0.\n",
      "Grade Results\n",
      "Question 1: 0/0.\n"
     ]
    }
   ],
   "source": [
    "#Question tests\n",
    "\n",
    "empty = \"question {}\"\n",
    "interpret(empty)\n",
    "\n",
    "trivial_passing = \"question { assert 1 == 1; }\"\n",
    "interpret(trivial_passing)\n",
    "\n",
    "trivial_failing = \"question { assert 0 == 1; }\"\n",
    "interpret(trivial_failing)\n",
    "\n",
    "testing_output = \"\"\"\n",
    "question {\n",
    "    run \"echo hello world\";\n",
    "    assert \"hello world\" in stdout;\n",
    "}\n",
    "\"\"\"\n",
    "interpret(testing_output)\n",
    "\n",
    "testing_exit_success = \"\"\"\n",
    "question {\n",
    "    run \"echo hello world\";\n",
    "    assert exit successful;\n",
    "}\n",
    "\"\"\"\n",
    "interpret(testing_exit_success)\n",
    "\n",
    "testing_create_string=\"\"\"\n",
    "    question \\\"string\\\"{\n",
    "        let x be String();\n",
    "        run \"echo\", x;\n",
    "        assert x in stdout;\n",
    "        award 10;\n",
    "    }\n",
    "\"\"\"\n",
    "interpret(testing_create_string)\n",
    "\n",
    "interpret(testing_exit_success)\n",
    "\n",
    "name_string = 'question \"named\" {}'\n",
    "interpret(name_string)\n",
    "\n",
    "name_int = 'question 1 {}'\n",
    "interpret(name_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade Results\n",
      "Grade Results\n",
      "Grade Results\n"
     ]
    }
   ],
   "source": [
    "#Teardown tests\n",
    "empty = \"teardown {}\"\n",
    "interpret(empty)\n",
    "\n",
    "trivial_passing = \"teardown { assert 1 == 1; }\"\n",
    "interpret(trivial_passing)\n",
    "\n",
    "trivial_failing = \"teardown { assert 0 == 1; }\"\n",
    "interpret(trivial_failing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade Results\n",
      "{\n",
      "    \"tests\": []\n",
      "}\n",
      "# Results\n",
      "## Score: 0/0\n"
     ]
    }
   ],
   "source": [
    "#Output tests\n",
    "empty = \"output {}\"\n",
    "interpret(empty)\n",
    "\n",
    "json = 'output { json; }'\n",
    "interpret(json)\n",
    "\n",
    "markdown = 'output { markdown; }'\n",
    "interpret(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Grade Results\n",
      "Question 0: 0/0.\n",
      "Exception thrown: AssertionError(\"False was not true! ('==', ('integer', 1), ('integer', 0))\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tom/gradelang/gradelang/interpreter.py\", line 62, in worker\n",
      "    walk(setup)\n",
      "  File \"/home/tom/gradelang/gradelang/walk.py\", line 151, in walk\n",
      "    return dispatch[action](ast)\n",
      "  File \"/home/tom/gradelang/gradelang/walk.py\", line 133, in <lambda>\n",
      "    'seq': lambda ast: (walk(ast[1]), walk(ast[2])),\n",
      "  File \"/home/tom/gradelang/gradelang/walk.py\", line 151, in walk\n",
      "    return dispatch[action](ast)\n",
      "  File \"/home/tom/gradelang/gradelang/walk.py\", line 60, in <lambda>\n",
      "    'assert': lambda ast: __assert(walk(ast[1]), ast[1]),\n",
      "  File \"/home/tom/gradelang/gradelang/walk.py\", line 50, in __assert\n",
      "    raise AssertionError(f'{cond} was not true! {message}')\n",
      "AssertionError: False was not true! ('==', ('integer', 1), ('integer', 0))\n",
      "\n",
      "{\n",
      "    \"tests\": [\n",
      "        {\n",
      "            \"name\": \"1\",\n",
      "            \"max_score\": 10,\n",
      "            \"score\": 10,\n",
      "            \"output\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"2\",\n",
      "            \"max_score\": 20,\n",
      "            \"score\": 20,\n",
      "            \"output\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"3\",\n",
      "            \"max_score\": 50,\n",
      "            \"score\": 50,\n",
      "            \"output\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Testing programs\n",
    "empty =\"\"\"\n",
    "setup {}\n",
    "question {}\n",
    "teardown {}\n",
    "output {}\n",
    "\"\"\"\n",
    "interpret(empty)\n",
    "\n",
    "setup_failure = \"\"\"\n",
    "setup { assert 1 == 0; }\n",
    "question { assert 1 == 1; }\n",
    "teardown {}\n",
    "output {}\n",
    "\"\"\"\n",
    "interpret(setup_failure)\n",
    "\n",
    "proposal = \"\"\"\n",
    "setup {\n",
    "    touch \"@/temp.txt\";\n",
    "    run \"echo\";\n",
    "    assert exit successful;\n",
    "}\n",
    "\n",
    "teardown {\n",
    "    remove \"@/temp.txt\";\n",
    "}\n",
    "\n",
    "output {\n",
    "    json;\n",
    "}\n",
    "\n",
    "question 1 {\n",
    "    # Run the program, saving output.\n",
    "    run \"echo\", \"hello world\";\n",
    "\n",
    "    # Now let's run some checks.\n",
    "    assert exit successful;\n",
    "\n",
    "    # This checks both stdout and stderr\n",
    "    assert \"hello\" in stdout;\n",
    "\n",
    "    award 10;\n",
    "}\n",
    "\n",
    "question 2  {\n",
    "    run \"echo\", \"hello world\";\n",
    "    assert \"goodbye\" not in stdout;\n",
    "    award 10;\n",
    "    assert \"hello\" in stdout;\n",
    "    assert \"hello\" not in stderr;\n",
    "    award 10;\n",
    "}\n",
    "\n",
    "question 3 {\n",
    "    let x be Float(minvalue=1);\n",
    "    run \"echo\", x;\n",
    "\n",
    "    # If we want to just look at stdout.\n",
    "    assert x in stdout;\n",
    "\n",
    "    String y = \"fish\";\n",
    "    run \"echo\", y;\n",
    "    assert \"fish\" in stdout;\n",
    "\n",
    "    let z be String();\n",
    "    run \"echo\", z;\n",
    "    assert z in stdout;\n",
    "\n",
    "    let camel be Int(min_value=6);\n",
    "    run \"echo\", camel;\n",
    "    assert camel in stdout;\n",
    "\n",
    "    award 50;\n",
    "}\n",
    "\"\"\"\n",
    "interpret(proposal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We successfully created a simple, easy to use language to work with the Grade autograding framework. We believe that this\n",
    "will make it easier to efficiently grade assignments. We also think our language will be natural and easy to learn\n",
    "for anyone who has used an autograder in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}